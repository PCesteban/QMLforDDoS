{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aL2B34hxfDcM"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "\n",
    "import pennylane as qml\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "import sklearn.decomposition\n",
    "\n",
    "import keras.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7-NUO4ikeKoF"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('DrDoS_SSDP_features_removed.csv', skiprows=[i for i in range(1,141550)], skipfooter=141547, engine=\"python\")\n",
    "\n",
    "n_features = 2\n",
    "x = StandardScaler().fit_transform(np.array(data.drop(columns=['Label'])))\n",
    "y = np.array(data['Label'].astype('category').cat.codes.astype(int))\n",
    "\n",
    "np.random.seed(1967)\n",
    "x, y = zip(*np.random.permutation(list(zip(x, y))))\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components=n_features)\n",
    "pca.fit(x)\n",
    "x = pca.transform(x)\n",
    "\n",
    "minmax_scale = MinMaxScaler((-1, 1)).fit(x)\n",
    "x = minmax_scale.transform(x)\n",
    "\n",
    "\n",
    "trainX, testX, trainy, testy = train_test_split(x, y, stratify=y, test_size=0.3, random_state=109)\n",
    "\n",
    "trainy = tf.one_hot(trainy, depth=2)\n",
    "testy = tf.one_hot(testy, depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2SpwzcOLxu37"
   },
   "outputs": [],
   "source": [
    "n_qubits = 2\n",
    "layers = 1\n",
    "data_dimension = 2\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    qml.templates.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "\n",
    "weight_shapes = {\"weights\": (layers,n_qubits,3)}\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(n_qubits,activation='relu',input_dim=2))\n",
    "model.add(qml.qnn.KerasLayer(qnode, weight_shapes, output_dim=n_qubits))\n",
    "model.add(tf.keras.layers.Dense(data_dimension, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5ZWr19AxnIN",
    "outputId": "e9d13262-fb9b-452e-cbe5-ca3b0e455929"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "413/413 [==============================] - 146s 352ms/step - loss: 0.4131 - accuracy: 0.8349 - val_loss: 0.0577 - val_accuracy: 0.9995\n",
      "Epoch 2/30\n",
      "413/413 [==============================] - 156s 377ms/step - loss: 0.0238 - accuracy: 0.9995 - val_loss: 0.0121 - val_accuracy: 0.9995\n",
      "Epoch 3/30\n",
      "413/413 [==============================] - 144s 348ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 0.0078 - val_accuracy: 0.9995\n",
      "Epoch 4/30\n",
      "413/413 [==============================] - 145s 351ms/step - loss: 0.0073 - accuracy: 0.9995 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 5/30\n",
      "413/413 [==============================] - 143s 347ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.0057 - val_accuracy: 0.9995\n",
      "Epoch 6/30\n",
      "413/413 [==============================] - 143s 347ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 0.0051 - val_accuracy: 0.9995\n",
      "Epoch 7/30\n",
      "413/413 [==============================] - 127s 309ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 0.0048 - val_accuracy: 0.9995\n",
      "Epoch 8/30\n",
      "413/413 [==============================] - 121s 293ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.0046 - val_accuracy: 0.9995\n",
      "Epoch 9/30\n",
      "413/413 [==============================] - 122s 296ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.0043 - val_accuracy: 0.9995\n",
      "Epoch 10/30\n",
      "413/413 [==============================] - 123s 298ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0040 - val_accuracy: 0.9995\n",
      "Epoch 11/30\n",
      "413/413 [==============================] - 123s 298ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.0039 - val_accuracy: 0.9995\n",
      "Epoch 12/30\n",
      "413/413 [==============================] - 123s 298ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.0037 - val_accuracy: 0.9995\n",
      "Epoch 13/30\n",
      "413/413 [==============================] - 122s 296ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9995\n",
      "Epoch 14/30\n",
      "413/413 [==============================] - 121s 292ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0038 - val_accuracy: 0.9995\n",
      "Epoch 15/30\n",
      "413/413 [==============================] - 123s 298ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.0048 - val_accuracy: 0.9995\n",
      "Epoch 16/30\n",
      "413/413 [==============================] - 122s 296ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
      "Epoch 17/30\n",
      "413/413 [==============================] - 122s 296ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "Epoch 18/30\n",
      "413/413 [==============================] - 125s 302ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0037 - val_accuracy: 0.9995\n",
      "Epoch 19/30\n",
      "413/413 [==============================] - 123s 297ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0034 - val_accuracy: 0.9995\n",
      "Epoch 20/30\n",
      "413/413 [==============================] - 122s 295ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.0043 - val_accuracy: 0.9995\n",
      "Epoch 21/30\n",
      "413/413 [==============================] - 121s 294ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "Epoch 22/30\n",
      "413/413 [==============================] - 118s 285ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0074 - val_accuracy: 0.9981\n",
      "Epoch 23/30\n",
      "413/413 [==============================] - 120s 291ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9995\n",
      "Epoch 24/30\n",
      "413/413 [==============================] - 117s 283ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9995\n",
      "Epoch 25/30\n",
      "413/413 [==============================] - 122s 296ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "Epoch 26/30\n",
      "413/413 [==============================] - 123s 298ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "Epoch 27/30\n",
      "413/413 [==============================] - 122s 295ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9995\n",
      "Epoch 28/30\n",
      "413/413 [==============================] - 122s 294ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0030 - val_accuracy: 0.9995\n",
      "Epoch 29/30\n",
      "413/413 [==============================] - 123s 297ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0030 - val_accuracy: 0.9995\n",
      "Epoch 30/30\n",
      "413/413 [==============================] - 122s 296ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9995\n",
      "CPU times: user 1h 3min 23s, sys: 34.4 s, total: 1h 3min 58s\n",
      "Wall time: 1h 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(trainX, trainy, validation_data=(trainX, trainy), epochs=30, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMPYgeTg9BtW",
    "outputId": "0f44f3a8-8b81-40a7-fb94-da7aef5875b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4881068e-05, 9.9997509e-01],\n",
       "       [3.2592427e-05, 9.9996746e-01],\n",
       "       [9.9999022e-01, 9.7645880e-06],\n",
       "       ...,\n",
       "       [6.0318478e-05, 9.9993968e-01],\n",
       "       [1.1297456e-04, 9.9988699e-01],\n",
       "       [2.3335928e-05, 9.9997663e-01]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predy = model.predict(testX)\n",
    "predy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "mDMNnf4UAC6m",
    "outputId": "57befd8a-bafc-4914-f85c-39aea7fc1b1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_labels_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "123vxSC5AK9o",
    "outputId": "b9c6fa6b-44bd-4266-a02e-a38ce4db1979"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, recall_score\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, make_scorer\n",
    "\n",
    "#Metrics\n",
    "classification = classification_report(rounded_labels_real, rounded_labels_pred)\n",
    "confusion = confusion_matrix(rounded_labels_real, rounded_labels_pred)\n",
    "    \n",
    "    # Accuracy\n",
    "accuracy = round(accuracy_score(rounded_labels_real, rounded_labels_pred)*100,5)\n",
    "    \n",
    "    # Recall\n",
    "recall = round(recall_score(rounded_labels_real, rounded_labels_pred, average='macro')*100,5)\n",
    "    \n",
    "    # Precision\n",
    "precision = round(precision_score(rounded_labels_real, rounded_labels_pred, average='weighted')*100,5)\n",
    "    \n",
    "    # F1\n",
    "f1 = round(f1_score(rounded_labels_real, rounded_labels_pred, average='weighted')*100,5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.88701\n",
      "99.88713\n",
      "99.88726\n",
      "99.88701\n",
      "0.001129900000000017\n",
      "CPU times: user 43min 50s, sys: 11.8 s, total: 44min 2s \n",
      " Wall time: 43min 45s\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)\n",
    "print(recall)\n",
    "print(precision)\n",
    "print(f1)\n",
    "print(1-(accuracy/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0: ──RX(0.067)──Rot(-0.071, -0.033, 0.591)──╭C──╭X──┤ ⟨Z⟩ \n",
      " 1: ──RX(1.317)──Rot(1.571, -1.375, 0.309)───╰X──╰C──┤ ⟨Z⟩ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(qnode.draw())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "iris-ds-pennylane-angle-embedding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
